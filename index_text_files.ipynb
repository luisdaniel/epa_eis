{
 "metadata": {
  "name": "",
  "signature": "sha256:7a79be482c56c988ed9d017c5ecfbede52791008e6a61a08217e60615be18209"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "from boto.s3.connection import S3Connection\n",
      "from boto.s3.key import Key\n",
      "import codecs\n",
      "import pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "json_data=open('k.json')\n",
      "keys = json.load(json_data)\n",
      "json_data.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from elasticsearch import Elasticsearch as ES, RequestsHttpConnection as RC \n",
      "host_params = {'host':keys['es_host'], 'port':80, 'use_ssl':False}\n",
      "es = ES([host_params], connection_class=RC, http_auth=(keys['es_user'], keys['es_pass']),  use_ssl=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn = S3Connection(keys['aws_key'], keys['aws_secret'])\n",
      "bucket = conn.get_bucket('epaeis')\n",
      "bucket.list()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "<boto.s3.bucketlistresultset.BucketListResultSet at 0x10107d850>"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text=''\n",
      "f = open('test.txt', mode='rt')\n",
      "text = f.read().encode(\"base64\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "test_post = {\n",
      "            \"title\": \"Test Document\",\n",
      "            \"body\": text\n",
      "        }\n",
      "print es.index(\n",
      "            index=\"test_post\",  \n",
      "            doc_type=\"post\",\n",
      "            body=test_post,\n",
      "            id=1\n",
      "        )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curl -X PUT \"localhost:9200/test\" -d '{\n",
      "  \"settings\" : { \"index\" : { \"number_of_shards\" : 1, \"number_of_replicas\" : 0 }}\n",
      "}'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curl -X PUT \"localhost:9200/test/attachment/_mapping\" -d '{\n",
      "  \"attachment\" : {\n",
      "    \"properties\" : {\n",
      "      \"file\" : {\n",
      "        \"type\" : \"attachment\",\n",
      "        \"fields\" : {\n",
      "          \"title\" : { \"store\" : \"yes\" },\n",
      "          \"file\" : { \"term_vector\":\"with_positions_offsets\", \"store\":\"yes\" }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curl \"localhost:9200/_cat/indices?v\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curl -u thegovlab:myvguoilbgfw \"ec2-54-173-220-218.compute-1.amazonaws.com/_cat/indices?v\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curl -X DELETE \"localhost:9200/test\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Mapping for documents\n",
      "curl -X PUT \"localhost:9200/eis_PDF/attachment/_mapping\" -d '{\n",
      "  \"attachment\" : {\n",
      "    \"properties\" : {\n",
      "      \"file\" : {\n",
      "        \"type\" : \"attachment\",\n",
      "        \"fields\" : {\n",
      "            \"title\" : { \"store\" : \"yes\" },\n",
      "            \"file\" : { \"term_vector\":\"with_positions_offsets\", \"store\":\"yes\" },\n",
      "            \"content_type\": {\"type\":\"string\", \"store\":\"yes\"},\n",
      "            \"date\" : {\"store\" : \"yes\"},\n",
      "            \"keywords\" : {\"store\" : \"yes\", \"analyzer\":\"keyword\"},\n",
      "            \"content_length\" : {\"store\" : \"yes\"}\n",
      "        }\n",
      "      },\n",
      "        \"eis\": {\n",
      "            \"type\":\"string\"\n",
      "        },\n",
      "        \"doc_type\": {\n",
      "            \"type\":\"string\"\n",
      "        },\n",
      "        \"file_url\": {\n",
      "            \"type\":\"string\"\n",
      "        }\n",
      "    }\n",
      "  }\n",
      "}'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Search by contents in file\n",
      "curl \"localhost:9200/eistxt/_search?pretty=true\" -d '{\n",
      "  \"fields\" : [\"file_url\", \"eis\", \"title\"],\n",
      "  \"query\" : {\n",
      "    \"query_string\" : {\n",
      "      \"query\" : \"transportation and texas\"\n",
      "    }\n",
      "  },\n",
      "  \"highlight\" : {\n",
      "    \"fields\" : {\n",
      "      \"file\" : {}\n",
      "    }\n",
      "  }\n",
      "}'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#index document (bash script)\n",
      "\n",
      "#!/bin/sh\n",
      "coded=`cat $1 | perl -MMIME::Base64 -ne 'print encode_base64($_)'`\n",
      "json=\"{\\\"file\\\":\\\"${coded}\\\",\\\"file_name\\\":\\\"$1\\\", \\\"eis\\\":\\\"$2\\\", \\\"doc_type\\\":\\\"$3\\\"}\"\n",
      "echo \"$json\" > json.file\n",
      "curl -X POST \"localhost:9200/test/attachment/\" -d @json.file\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#---SERACH BY EIS\n",
      "curl \"localhost:9200/eispdf/_search?pretty=true\" -d '{\n",
      "    \"fields\": [\"file_name\", \"eis\", \"file_url\"],\n",
      "    \"query\" : {\n",
      "        \"filtered\" : {\n",
      "            \"filter\" : {\n",
      "                \"term\" : {\n",
      "                    \"eis\" : \"20080540\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#---SERACH BY FILE URL\n",
      "curl \"localhost:9200/eispdf/_search?pretty=true\" -d '{\n",
      "    \"fields\": [\"file_name\", \"eis\"],\n",
      "    \"query\" : {\n",
      "        \"match\" : {\n",
      "            \"file_url\" : \"01-02-2009/20080540/20080540.pdf\"\n",
      "        }\n",
      "    }\n",
      "}'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#connect to S3\n",
      "#settings for connecting to ElasticSearch\n",
      "#get PDF\n",
      "#check if text file exists\n",
      "    #if no text file, try to create it.\n",
      "    #if can't create, add file to list. \n",
      "#if exists, index it.\n",
      "#go to next file.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Import stuff\n",
      "import json\n",
      "from boto.s3.connection import S3Connection\n",
      "from boto.s3.key import Key\n",
      "import codecs\n",
      "import pickle\n",
      "import os\n",
      "import subprocess\n",
      "from datetime import datetime\n",
      "\n",
      "#get keys\n",
      "json_data=open('k.json')\n",
      "keys = json.load(json_data)\n",
      "json_data.close()\n",
      "\n",
      "#connect to ES\n",
      "from elasticsearch import Elasticsearch as ES, RequestsHttpConnection as RC \n",
      "host_params = {'host':keys['es_host'], 'port':80, 'use_ssl':False}\n",
      "es = ES([host_params], connection_class=RC, http_auth=(keys['es_user'], keys['es_pass']),  use_ssl=False)\n",
      "\n",
      "#connect to S3\n",
      "conn = S3Connection(keys['aws_key'], keys['aws_secret'])\n",
      "bucket = conn.get_bucket('epaeis')\n",
      "bucket.list()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 266,
       "text": [
        "<boto.s3.bucketlistresultset.BucketListResultSet at 0x10fdfc250>"
       ]
      }
     ],
     "prompt_number": 266
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HOST = keys['es_host']\n",
      "USER = keys['es_user']\n",
      "PASS = keys['es_pass']\n",
      "INDEX = 'eispdf'\n",
      "TYPE = 'attachment'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 267
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#test connection\n",
      "cmd = \"curl -u {}:{} \\\"{}/_cat/indices?v\\\"\".format(keys['es_user'], keys['es_pass'], keys['es_host'])\n",
      "os.system(cmd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 260,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 260
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clear_and_map():\n",
      "    #clear and create all new mapping.\n",
      "    HOST = keys['es_host']\n",
      "    USER = keys['es_user']\n",
      "    PASS = keys['es_pass']\n",
      "    INDEX = 'eispdf'\n",
      "    TYPE = 'attachment'\n",
      "    print \"Clearing old index and creating new one with mapping.\"\n",
      "\n",
      "    cmd = \"curl -u {}:{} -X DELETE \\\"{}/{}\\\"\".format(USER, PASS, HOST, INDEX)\n",
      "    os.system(cmd)\n",
      "\n",
      "    #create index\n",
      "    cmd = \"curl -u {}:{} -X PUT \\\"{}/{}\\\"\".format(USER, PASS, HOST, INDEX)\n",
      "    os.system(cmd)\n",
      "\n",
      "    #create mapping\n",
      "    cmd = \"curl -u {}:{} -X PUT \\\"{}/{}/{}/_mapping\\\" -d \\'\".format(USER, PASS, HOST, INDEX, TYPE)\n",
      "    cmd +='''{\n",
      "      \"attachment\" : {\n",
      "        \"properties\" : {\n",
      "          \"file\" : {\n",
      "            \"type\" : \"attachment\",\n",
      "            \"fields\" : {\n",
      "                \"title\" : { \"store\" : \"yes\" },\n",
      "                \"file\" : { \"term_vector\":\"with_positions_offsets\", \"store\":\"yes\" },\n",
      "                \"content_type\": {\"type\":\"string\", \"store\":\"yes\"},\n",
      "                \"date\" : {\"store\" : \"yes\"},\n",
      "                \"keywords\" : {\"store\" : \"yes\", \"analyzer\":\"keyword\"},\n",
      "                \"content_length\" : {\"type\":\"string\", \"store\" : \"yes\"}\n",
      "            }\n",
      "          },\n",
      "            \"eis\": {\n",
      "                \"type\":\"string\",\n",
      "                \"index\":\"not_analyzed\"\n",
      "            },\n",
      "            \"file_url\": {\n",
      "                \"type\":\"string\",\n",
      "                \"index\":\"not_analyzed\"\n",
      "            }\n",
      "        }\n",
      "      }\n",
      "    }\\''''\n",
      "    os.system(cmd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 246
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clear_and_map()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Clearing old index and creating new one with mapping.\n"
       ]
      }
     ],
     "prompt_number": 256
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#can we check wether a file has already been indexed\n",
      "def index_exists(file_url):\n",
      "    res = es.search(index=INDEX, body={\n",
      "        \"fields\": ['eis'],\n",
      "        \"query\" : {\n",
      "            \"filtered\" : {\n",
      "                \"filter\" : {\n",
      "                    \"term\" : {\n",
      "                        \"file_url\" : file_url\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    })\n",
      "    return res['hits']['hits']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 255
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def index_file(file_url, file_name):\n",
      "    title = file_url[20:].replace(\"-\", \" \").replace(\".pdf\",\"\").replace(\".txt\",\"\").title()\n",
      "    eis = file_url[11:19]\n",
      "    epa_date = file_url[:10].replace(\"-\",\"/\")\n",
      "    file64 = open(file_name, \"rb\").read().encode(\"base64\")\n",
      "    f = open('temp.json', 'w')\n",
      "    data = { \n",
      "        'file': file64, \n",
      "        'title': title, \n",
      "        'eis': eis, \n",
      "        'file_url':file_url\n",
      "    }\n",
      "    json.dump(data, f) # dump json to tmp file\n",
      "    f.close()\n",
      "    print \"Gonna make curl post for: \" + file_url\n",
      "    cmd = 'curl -u {}:{} -X POST \"{}/{}/{}\" -d @'.format(USER, PASS, HOST,INDEX,TYPE)\n",
      "    cmd += 'temp.json'\n",
      "    os.system(cmd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 281
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#index all files\n",
      "def index_all_files():\n",
      "    unindexed = []\n",
      "    #get file from S3\n",
      "    rs = bucket.list()\n",
      "    for key in rs:\n",
      "        if key.name[len(key.name)-4:] == '.pdf': #only PDF's\n",
      "            try:\n",
      "                print \"Getting: \" + key.name\n",
      "                file_key = bucket.get_key(key.name)\n",
      "                temp_file = file_key.get_contents_to_filename('temp_file.pdf')\n",
      "                if index_exists(key.name):\n",
      "                    print \"file already indexed\"\n",
      "                    #add to a list or something.\n",
      "                    unindexed.append(key.name + \"|repeat\")\n",
      "                else:\n",
      "                    index_file(key.name, 'temp_file.pdf')\n",
      "                #os.remove('temp_file.pdf')\n",
      "            except Exception, e:\n",
      "                print \"Could not get file: \" + str(e)\n",
      "                unindexed.append(key.name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 257
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index_all_files()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting: 01-02-2009/20080540/20080540.pdf\n",
        "Getting: 01-02-2009/20080541/20080541.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-02-2009/20080542/20080542.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/20130381.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-abstract.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-cover.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-list-of-acronyms-and-abbreviations.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-list-of-agencies-to-whom.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-list-of-preparers.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-references.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-section-10-need-and-purpose.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-section-20-alternatives.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-section-30-affected-environment.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-section-40-environmental-consequences.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-section-50-draft-section-4f-evaluation.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-section-60-indirect-effects.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-section-70-cumulative-effects.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-section-80-public-involvement.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-section-90-environmental-permits-issues-and-commitments.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-signature-page.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-summary.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/_us-181-harbor-bridge-draft-eis-table-of-contents.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/appendix-a_figures__summary.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/appendix-a_figures_section-10.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/appendix-a_figures_section-20.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting: 01-03-2014/20130381/appendix-a_figures_section-3138.pdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-258-fe856c7d0c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindex_all_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-257-a058eed76289>\u001b[0m in \u001b[0;36mindex_all_files\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Getting: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mfile_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbucket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mtemp_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_contents_to_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'temp_file.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mindex_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"file already indexed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/boto/s3/key.pyc\u001b[0m in \u001b[0;36mget_contents_to_filename\u001b[0;34m(self, filename, headers, cb, num_cb, torrent, version_id, res_download_handler, response_headers)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                                           \u001b[0mversion_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversion_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m                                           \u001b[0mres_download_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_download_handler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m                                           response_headers=response_headers)\n\u001b[0m\u001b[1;32m   1711\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/boto/s3/key.pyc\u001b[0m in \u001b[0;36mget_contents_to_file\u001b[0;34m(self, fp, headers, cb, num_cb, torrent, version_id, res_download_handler, response_headers)\u001b[0m\n\u001b[1;32m   1646\u001b[0m                 self.get_file(fp, headers, cb, num_cb, torrent=torrent,\n\u001b[1;32m   1647\u001b[0m                               \u001b[0mversion_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversion_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m                               response_headers=response_headers)\n\u001b[0m\u001b[1;32m   1649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m     def get_contents_to_filename(self, filename, headers=None,\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/boto/s3/key.pyc\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(self, fp, headers, cb, num_cb, torrent, version_id, override_num_retries, response_headers)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                 \u001b[0mresponse_headers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse_headers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                 \u001b[0mhash_algs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                 query_args=None)\n\u001b[0m\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m     def _get_file_internal(self, fp, headers=None, cb=None, num_cb=10,\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/boto/s3/key.pyc\u001b[0m in \u001b[0;36m_get_file_internal\u001b[0;34m(self, fp, headers, cb, num_cb, torrent, version_id, override_num_retries, response_headers, hash_algs, query_args)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m                 \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m                 \u001b[0mdata_len\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0malg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdigesters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 258
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'01-02-2009/20080540/20080540.pdf'[20:].replace(\"-\", \" \").replace(\".pdf\",\"\").title()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 174,
       "text": [
        "'20080540'"
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curl \"localhost:9200/eispdf/_search?pretty=true\" -d '{\n",
      "  \"fields\" : [\"title\", \"eis\"],\n",
      "  \"query\" : {\n",
      "    \"match\" : {\n",
      "      \"file\" : \"bridge\"\n",
      "    }\n",
      "  },\n",
      "  \"highlight\" : {\n",
      "    \"fields\" : {\n",
      "      \"file\" : {}\n",
      "    }\n",
      "  }\n",
      "}'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def index_individual(file_url):\n",
      "    try:\n",
      "        print \"Getting: \" + file_url\n",
      "        file_key = bucket.get_key(file_url)\n",
      "        #add this\n",
      "        print file_key.size\n",
      "        if file_key.size > 100000000:\n",
      "            print \"Too large, using txt file\"\n",
      "            file_url = file_url.replace(\".pdf\", \".txt\")\n",
      "            file_key = bucket.get_key(file_url)\n",
      "            temp_file_name = 'temp_file.txt'\n",
      "            temp_file = file_key.get_contents_to_filename(temp_file_name)\n",
      "            print \"Got text file\"\n",
      "        else:\n",
      "            print \"size ok, using pdf\"\n",
      "            temp_file_name = 'temp_file.pdf'\n",
      "            temp_file = file_key.get_contents_to_filename(temp_file_name)\n",
      "            #end add, change index_file function below.\n",
      "        if index_exists(file_url):\n",
      "            print \"file already indexed\"\n",
      "            #add to a list or something.\n",
      "        else:\n",
      "            print \"Not indexed, going to index: \" + file_url\n",
      "            index_file(file_url, temp_file_name)\n",
      "        #os.remove(temp_file_name)\n",
      "    except Exception, e:\n",
      "        print \"Could not get file: \" + str(e)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 279
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index_individual('06-08-2012/20120180/eis_for_the_basing_of_v22h1_aircraft_in_hawaii_vol2_appendices.pdf')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting: 06-08-2012/20120180/eis_for_the_basing_of_v22h1_aircraft_in_hawaii_vol2_appendices.pdf\n",
        "185291325"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Too large, using txt file\n",
        "Got text file"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Not indexed, going to index: 06-08-2012/20120180/eis_for_the_basing_of_v22h1_aircraft_in_hawaii_vol2_appendices.txt\n",
        "Gonna make curl post for: 06-08-2012/20120180/eis_for_the_basing_of_v22h1_aircraft_in_hawaii_vol2_appendices.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 282
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'06-08-2012/20120180/eis_for_the_basing_of_v22h1_aircraft_in_hawaii_vol2_appendices.pdf'[20:].replace(\"-\", \" \").replace(\".pdf\",\"\").title()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 271,
       "text": [
        "'Eis_For_The_Basing_Of_V22H1_Aircraft_In_Hawaii_Vol2_Appendices'"
       ]
      }
     ],
     "prompt_number": 271
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_url = '06-08-2012/20120180/eis_for_the_basing_of_v22h1_aircraft_in_hawaii_vol2_appendices.pdf'\n",
      "file_key = bucket.get_key(file_url)\n",
      "file_key.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 272,
       "text": [
        "185291325"
       ]
      }
     ],
     "prompt_number": 272
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def index_exists(file_url):\n",
      "    res = es.search(index=INDEX, body={\n",
      "        \"fields\": ['eis'],\n",
      "        \"query\" : {\n",
      "            \"filtered\" : {\n",
      "                \"filter\" : {\n",
      "                    \"term\" : {\n",
      "                        \"file_url\" : file_url\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    })\n",
      "    return res['hits']['total']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 286
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###------ find unindexed stuff\n",
      "import csv\n",
      "import urllib2\n",
      "import re\n",
      "unindexed = []\n",
      "repeated = []\n",
      "indexed = []\n",
      "with open('reports.csv', mode='r') as infile:\n",
      "        reader = csv.reader(infile)\n",
      "        for row in reader:\n",
      "            if row[21] != 'list_of_links' and row[20] !=0:\n",
      "                links = row[21].split()\n",
      "                for link in links:\n",
      "                    file_name = urllib2.unquote(link)\n",
      "                    file_name = file_name[file_name.index('$file')+6:].replace(\".pdf\",\"\")\n",
      "                    file_name = re.sub(r'([^\\s\\w])+', '', file_name).replace(\" \", \"-\").lower() + \".pdf\"\n",
      "                    file_name = row[1].replace(\"/\", \"-\") + \"/\" + row[7] + \"/\" + file_name\n",
      "                    num_found = index_exists(file_name)\n",
      "                    if num_found == 0:\n",
      "                        unindexed.append(link)\n",
      "                        print \"Unindexed: \" + link\n",
      "                    if num_found == 1:\n",
      "                        indexed.append(link)\n",
      "                    if num_found > 1:\n",
      "                        repeated.append(link)\n",
      "                        print \"Repeated: \" + link"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(indexed)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 294,
       "text": [
        "3404"
       ]
      }
     ],
     "prompt_number": 294
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}