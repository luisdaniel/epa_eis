{
 "metadata": {
  "name": "",
  "signature": "sha256:47966894b565e6db6552360195ce0d63a6e0821b577fa11afa5198b050912bd6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup as bs\n",
      "import re\n",
      "import urllib2\n",
      "import httplib\n",
      "import csv\n",
      "import json\n",
      "import datetime\n",
      "import pandas as pd\n",
      "import os\n",
      "from boto.s3.connection import S3Connection\n",
      "from boto.s3.key import Key"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "json_data=open('k.json')\n",
      "keys = json.load(json_data)\n",
      "json_data.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn = S3Connection(keys['aws_key'], keys['aws_secret'])\n",
      "bucket = conn.get_bucket('epaeis')\n",
      "bucket.list()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "<boto.s3.bucketlistresultset.BucketListResultSet at 0x10c912d50>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columns = ['date', 'eis', 'link', 'error']\n",
      "df_missing_files = pd.DataFrame(columns=columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def save_files():\n",
      "    index_missing = 0\n",
      "    with open('reports.csv', mode='r') as infile:\n",
      "        reader = csv.reader(infile)\n",
      "        for row in reader:\n",
      "            if row[21] != 'list_of_links' and row[20] !=0:\n",
      "                print \"Getting links for: \" + row[5]\n",
      "                links = row[21].split()\n",
      "                for link in links:\n",
      "                    try:\n",
      "                        k = Key(bucket)\n",
      "                        file_name = urllib2.unquote(link)\n",
      "                        file_name = file_name[file_name.index('$file')+6:].replace(\".pdf\",\"\")\n",
      "                        file_name = re.sub(r'([^\\s\\w])+', '', file_name).replace(\" \", \"-\").lower() + \".pdf\"\n",
      "                        file_name = row[1].replace(\"/\", \"-\") + \"/\" + row[7] + \"/\" + file_name\n",
      "                        print \"Saving: \" + file_name\n",
      "                        if bucket.get_key(file_name):\n",
      "                            print \"File exists, skipping\"\n",
      "                        else:\n",
      "                            f = urllib2.urlopen(link)\n",
      "                            data = f.read()\n",
      "                            f.close()\n",
      "                            k = bucket.new_key(file_name)\n",
      "                            k.set_contents_from_string(data)\n",
      "                    except Exception, e:\n",
      "                        print \"Could not get because: \" + str(e)\n",
      "                        new_missing_row = [row[1], row[7], link, str(e)]\n",
      "                        df_missing_files.loc[index_missing] = new_missing_row\n",
      "                        index_missing +=1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_files()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if df_missing_files.shape[0]:\n",
      "    df_missing_files.to_csv('missing_files_to_save.csv', encoding='utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}