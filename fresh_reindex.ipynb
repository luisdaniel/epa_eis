{
 "metadata": {
  "name": "",
  "signature": "sha256:4b50bf42c2b0875fec0b6a1f597381191c5415d15f217235907feacd55b1b5e1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Import stuff\n",
      "import json\n",
      "from boto.s3.connection import S3Connection\n",
      "from boto.s3.key import Key\n",
      "import codecs\n",
      "import csv\n",
      "import os\n",
      "import sys\n",
      "import urllib2\n",
      "from datetime import datetime\n",
      "from bs4 import BeautifulSoup as bs\n",
      "import re\n",
      "import json\n",
      "from mongoengine import *\n",
      "import models\n",
      "import bson\n",
      "from bson import json_util\n",
      "import pandas as pd\n",
      "import httplib\n",
      "import subprocess\n",
      "\n",
      "#PDF Miner\n",
      "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
      "from pdfminer.converter import TextConverter\n",
      "from pdfminer.layout import LAParams\n",
      "from pdfminer.pdfpage import PDFPage\n",
      "from cStringIO import StringIO\n",
      "\n",
      "#get keys\n",
      "json_data=open('k.json')\n",
      "keys = json.load(json_data)\n",
      "json_data.close()\n",
      "HOST = keys['es_host']\n",
      "USER = keys['es_user']\n",
      "PASS = keys['es_pass']\n",
      "MONGO = keys['mongo_uri']\n",
      "INDEX = 'impactstatement'\n",
      "PARENT = 'report'\n",
      "\n",
      "#connect to ES\n",
      "from elasticsearch import Elasticsearch as ES, RequestsHttpConnection as RC \n",
      "host_params = {'host':keys['es_host'], 'port':80, 'use_ssl':False}\n",
      "es = ES([host_params], connection_class=RC, http_auth=(keys['es_user'], keys['es_pass']),  use_ssl=False)\n",
      "\n",
      "#connect to S3\n",
      "conn = S3Connection(keys['aws_key'], keys['aws_secret'])\n",
      "bucket = conn.get_bucket('epaeis')\n",
      "bucket.list()\n",
      "\n",
      "#connect to mongo\n",
      "connect('db', host=MONGO)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "MongoClient(u'ds051640.mongolab.com', 51640)"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clear_and_map():\n",
      "    #clear and create all new mapping.\n",
      "    print \"Clearing old index and creating new one with mapping.\"\n",
      "\n",
      "    cmd = \"curl -u {}:{} -X DELETE \\\"{}/{}\\\"\".format(USER, PASS, HOST, INDEX)\n",
      "    os.system(cmd)\n",
      "\n",
      "    #create index\n",
      "    cmd = \"curl -u {}:{} -X PUT \\\"{}/{}\\\"\".format(USER, PASS, HOST, INDEX)\n",
      "    os.system(cmd)\n",
      "\n",
      "    #create mapping\n",
      "    cmd = \"curl -u {}:{} -X PUT \\\"{}/{}/{}/_mapping?pretty=1\\\" -d \\'\".format(USER, PASS, HOST, INDEX, PARENT)\n",
      "    cmd +='''{\n",
      "        \"report\": {\n",
      "          \"_id\": {\n",
      "            \"index\":\"not_analyzed\",\n",
      "            \"store\": true\n",
      "          },\n",
      "          \"properties\": {\n",
      "            \"agency\" : {\n",
      "              \"type\" : \"string\"\n",
      "            },\n",
      "            \"agency_abbrev\" : {\n",
      "              \"type\" : \"string\",\n",
      "              \"index\" : \"not_analyzed\"\n",
      "            },\n",
      "            \"amended_notice\" : {\n",
      "              \"type\" : \"string\"\n",
      "            },\n",
      "            \"amended_notice_date\" : {\n",
      "              \"type\" : \"date\",\n",
      "              \"format\" : \"dateOptionalTime\"\n",
      "            },\n",
      "            \"comment_due_review_date\" : {\n",
      "              \"type\" : \"date\",\n",
      "              \"format\" : \"dateOptionalTime\"\n",
      "            },\n",
      "            \"comment_letter_date\" : {\n",
      "              \"type\" : \"date\",\n",
      "              \"format\" : \"dateOptionalTime\"\n",
      "            },\n",
      "            \"contact_name\" : {\n",
      "              \"type\" : \"string\"\n",
      "            },\n",
      "            \"contact_phone\" : {\n",
      "              \"type\" : \"string\"\n",
      "            },\n",
      "            \"date\" : {\n",
      "              \"type\" : \"date\",\n",
      "              \"format\" : \"dateOptionalTime\"\n",
      "            },\n",
      "            \"date_uploaded\" : {\n",
      "              \"type\" : \"date\",\n",
      "              \"format\" : \"dateOptionalTime\"\n",
      "            },\n",
      "            \"document_type\" : {\n",
      "              \"type\" : \"string\"\n",
      "            },\n",
      "            \"eis_number\" : {\n",
      "              \"type\" : \"string\",\n",
      "              \"index\" : \"not_analyzed\"\n",
      "            },\n",
      "            \"federal_register_date\" : {\n",
      "              \"type\" : \"date\",\n",
      "              \"format\" : \"dateOptionalTime\"\n",
      "            },\n",
      "            \"rating\" : {\n",
      "              \"type\" : \"string\",\n",
      "              \"index\" : \"not_analyzed\"\n",
      "            },\n",
      "            \"report_link\" : {\n",
      "              \"type\" : \"string\",\n",
      "              \"index\" : \"not_analyzed\"\n",
      "            },\n",
      "            \"state\" : {\n",
      "              \"type\" : \"string\"\n",
      "            },\n",
      "            \"state_abbrev\" : {\n",
      "              \"type\" : \"string\",\n",
      "              \"index\" : \"not_analyzed\"\n",
      "            },\n",
      "            \"supplemental_info\" : {\n",
      "              \"type\" : \"string\"\n",
      "            },\n",
      "            \"title\" : {\n",
      "              \"type\" : \"string\"\n",
      "            },\n",
      "            \"website\" : {\n",
      "              \"type\" : \"string\",\n",
      "              \"index\" : \"not_analyzed\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "    }\\''''\n",
      "    os.system(cmd)\n",
      "    cmd = \"curl -u {}:{} -X PUT \\\"{}/{}/{}/_mapping?pretty=1\\\" -d \\'\".format(USER, PASS, HOST, INDEX, 'eis_file')\n",
      "    cmd +='''{\n",
      "        \"eis_file\": {\n",
      "          \"_parent\": {\n",
      "            \"type\":\"report\"\n",
      "          },\n",
      "          \"properties\": {\n",
      "            \"file\": {\n",
      "              \"type\": \"attachment\",\n",
      "              \"fields\": {\n",
      "                \"title\" : { \"store\" : \"yes\" },\n",
      "                \"file\" : { \"term_vector\":\"with_positions_offsets\", \"store\":\"yes\" },\n",
      "                \"content_type\": {\"type\":\"string\", \"store\":\"yes\"},\n",
      "                \"date\" : {\"store\" : \"yes\"},\n",
      "                \"keywords\" : {\"store\" : \"yes\", \"analyzer\":\"keyword\"},\n",
      "                \"content_length\" : {\"type\":\"string\", \"store\" : \"yes\"}\n",
      "              }\n",
      "            },\n",
      "            \"file_url\": {\n",
      "                \"type\":\"string\",\n",
      "                \"index\":\"not_analyzed\"\n",
      "            },\n",
      "            \"eis_number\": {\n",
      "                \"type\": \"string\",\n",
      "                \"index\":\"not_analyzed\n",
      "            }\n",
      "            \"title\": {\n",
      "              \"type\":\"string\"\n",
      "            }\n",
      "        }\n",
      "      }\n",
      "    }\\''''\n",
      "    os.system(cmd)\n",
      "    cmd = \"curl -u {}:{} -X PUT \\\"{}/{}/{}/_mapping?pretty=1\\\" -d \\'\".format(USER, PASS, HOST, INDEX, 'comment_letter')\n",
      "    cmd +='''{\n",
      "      \"comment_letter\": {\n",
      "          \"_parent\": {\n",
      "            \"type\":\"report\"\n",
      "          },\n",
      "          \"properties\": {\n",
      "            \"file\": {\n",
      "              \"type\": \"attachment\",\n",
      "              \"fields\": {\n",
      "                \"title\" : { \"store\" : \"yes\" },\n",
      "                \"file\" : { \"term_vector\":\"with_positions_offsets\", \"store\":\"yes\" },\n",
      "                \"content_type\": {\"type\":\"string\", \"store\":\"yes\"},\n",
      "                \"date\" : {\"store\" : \"yes\"},\n",
      "                \"keywords\" : {\"store\" : \"yes\", \"analyzer\":\"keyword\"},\n",
      "                \"content_length\" : {\"type\":\"string\", \"store\" : \"yes\"}\n",
      "              }\n",
      "            },\n",
      "            \"file_url\": {\n",
      "                \"type\":\"string\",\n",
      "                \"index\":\"not_analyzed\"\n",
      "            },\n",
      "            \"eis_number\": {\n",
      "                \"type\": \"string\",\n",
      "                \"index\":\"not_analyzed\n",
      "            },\n",
      "            \"title\": {\n",
      "              \"type\":\"string\"\n",
      "            }\n",
      "        }\n",
      "      }\n",
      "    }\\''''\n",
      "    os.system(cmd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def index_all_reports():\n",
      "    data = pd.read_csv('reports.csv')\n",
      "    data = data.fillna('')\n",
      "    all_reports = [row[1]['eis_number'] for row in data.T.iteritems()]\n",
      "    for eis in all_reports:\n",
      "        print \"indexing: \" + str(eis)\n",
      "        report = models.Report.objects(eis_number=str(eis)).first()\n",
      "        if report:\n",
      "            doc = {\n",
      "                \"agency_abbrev\": report.agency[0],\n",
      "                \"amended_notice\": report.amended_notice,\n",
      "                \"amended_notice_date\": report.amended_notice_date,\n",
      "                \"comment_due_review_date\": report.comment_due_review_date,\n",
      "                \"comment_letter_date\": report.comment_letter_date,\n",
      "                \"contact_name\": report.contact_name,\n",
      "                \"contact_phone\": report.contact_phone,\n",
      "                \"date_uploaded\": report.date_uploaded,\n",
      "                \"date\": report.federal_register_date,\n",
      "                \"document_type\": report.document_type,\n",
      "                \"eis_number\": report.eis_number,\n",
      "                \"federal_register_date\": report.federal_register_date,\n",
      "                \"rating\": report.rating,\n",
      "                \"report_link\": report.report_link,\n",
      "                \"state_abbrev\": report.state[0],\n",
      "                \"supplemental_info\": report.supplemental_info.encode('utf-8'),\n",
      "                \"title\": report.title,\n",
      "                \"website\": report.website,\n",
      "            }\n",
      "            res = es.index(index=INDEX, doc_type=PARENT, id=eis, body=doc)\n",
      "            print res['created']\n",
      "        else: \n",
      "            print \"Report not found: \" + str(eis)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def index_all_report_files():\n",
      "    data = pd.read_csv('reports.csv')\n",
      "    data = data.fillna('')\n",
      "    all_reports = [row[1]['eis_number'] for row in data.T.iteritems()]\n",
      "    missing_data = {\n",
      "        \"eis\":[],\n",
      "        \"file_url\":[],\n",
      "        \"error\":[]\n",
      "    }\n",
      "    for eis in missing_reports:\n",
      "        report = models.Report.objects(eis_number=str(eis)).first()\n",
      "        if report:\n",
      "            for f in report.report_files:\n",
      "                file_url = f.file_url_s3.replace(\"https://s3.amazonaws.com/epaeis/\",\"\").replace(\".pdf\",\".txt\")\n",
      "                key = bucket.get_key(file_url)\n",
      "                if key:\n",
      "                    try:\n",
      "                        temp_file = key.get_contents_to_filename('temp.txt')\n",
      "                        file64 = open('temp.txt', \"rb\").read().encode(\"base64\")\n",
      "                        filejson = open('temp.json', 'w')\n",
      "                        data = { \n",
      "                            'file': file64, \n",
      "                            'title': f.title, \n",
      "                            'file_url':f.file_url_s3,\n",
      "                            'eis_number': eis\n",
      "                        }\n",
      "                        print \"Indexing: \" + file_url\n",
      "                        json.dump(data, filejson)\n",
      "                        filejson.close()\n",
      "                        cmd = 'curl -u {}:{} -X POST \"{}/{}/{}?parent={}\" -d @'.format(USER, PASS, HOST, INDEX, \"eis_file\", eis)\n",
      "                        cmd += 'temp.json'\n",
      "                        os.system(cmd)\n",
      "                        os.remove('temp.txt')\n",
      "                    except Exception, e:\n",
      "                        print \"Could not get: \" + file_url\n",
      "                        missing_data['eis'].append(eis)\n",
      "                        missing_data['file_url'].append(file_url)\n",
      "                        missing_data['error'].append(\"Could not find file on S3\")\n",
      "                else:\n",
      "                    print \"Could not get: \" + file_url\n",
      "                    missing_data['eis'].append(eis)\n",
      "                    missing_data['file_url'].append(file_url)\n",
      "                    missing_data['error'].append(\"Could not find file on S3\")\n",
      "    dataFrame = pd.DataFrame(missing_data)\n",
      "    dataFrame.to_csv('fresh_reindex_error_log.csv', encoding='utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}